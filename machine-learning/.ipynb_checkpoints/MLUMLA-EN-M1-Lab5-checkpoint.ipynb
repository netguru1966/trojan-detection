{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/logo.png\" alt=\"drawing\" width=\"400\" style=\"background-color:white; padding:1em;\" /></center> <br/>\n",
    "\n",
    "# ML through Application\n",
    "## Module 1, Lab 5: Using Advanced AutoGluon Techniques\n",
    "\n",
    "By the end of this document, you should be able to understand how to use [AutoGluon](https://auto.gluon.ai/stable/index.html#) to train a model and make a prediction on the full train dataset and generate a prediction file.\n",
    "\n",
    "You will learn how to do the following:\n",
    "\n",
    "- Train a model on a full dataset.\n",
    "- Limit the time that a model trains for.\n",
    "- Output a file that contains predictions.\n",
    "\n",
    "---\n",
    "\n",
    "You will explore a dataset that contains information about books. The goal is to predict book prices by using features about the books.\n",
    "\n",
    "__Business problem:__ Books from a large database with several features cannot be listed for sale because one critical piece of information is missing: the price. \n",
    "\n",
    "__ML problem description:__ Predict book prices by using book features, such as genre, release data, ratings, and number of reviews.\n",
    "\n",
    "This is a regression task (the training dataset has a book price column to use for labels). \n",
    "\n",
    "----\n",
    "\n",
    "You will be presented with two kinds of exercises throughout the notebook: activities and challenges. <br/>\n",
    "\n",
    "| <img style=\"float: center;\" src=\"images/activity.png\" alt=\"Activity\" width=\"125\"/>| <img style=\"float: center;\" src=\"images/challenge.png\" alt=\"Challenge\" width=\"125\"/>|\n",
    "| --- | --- |\n",
    "|<p style=\"text-align:center;\">No coding is needed for an activity. You try to understand a concept, <br/>answer questions, or run a code cell.</p> |<p style=\"text-align:center;\">Challenges are where you can practice your coding skills.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index\n",
    "\n",
    "- [Importing AutoGluon](#Importing-AutoGluon)\n",
    "- [Getting the data](#Getting-the-data)\n",
    "- [Model training with AutoGluon using the full dataset](#Model-training-with-AutoGluon-using-the-full-dataset)\n",
    "- [Model prediction with AutoGluon](#Model-prediction-with-AutoGluon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Importing AutoGluon\n",
    "\n",
    "Install and load the libraries that are needed to work with the tabular dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Install libraries\n",
    "!pip install -U -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import libraries and utility functions\n",
    "%load_ext autoreload\n",
    "import pandas as pd\n",
    "\n",
    "# Import the newly installed AutoGluon code library\n",
    "from autogluon.tabular import TabularPredictor, TabularDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Getting the data\n",
    "\n",
    "Next, load the dataset into a Pandas DataFrame and preview the first rows of data.\n",
    "\n",
    "__Note:__ You will use the [Amazon Product Reviews](https://cseweb.ucsd.edu/~jmcauley/datasets.html#amazon_reviews) dataset. For more information about this dataset, see the following resources:\n",
    "\n",
    "- Ruining He and Julian McAuley. \"Ups and Downs: Modeling the Visual Evolution of Fashion Trends with One-Class Collaborative Filtering.\" Proceedings of the 25th International Conference on World Wide Web, Geneva, Switzerland, April 2016. https://doi.org/10.1145/2872427.2883037.\n",
    "\n",
    "- Julian McAuley, Christopher Targett, Qinfeng Shi, Anton van den Hengel. \"Image-Based Recommendations on Styles and Substitutes.\" Proceedings of the 38th International Association for Computing Machinery (ACM) Special Interest Group on Information Retrieval (SIGIR) Conference on Research and Development in Information Retrieval, Santiago, Chile, August 2015. https://doi.org/10.1145/2766462.2767755."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = TabularDataset(data=\"data/train.csv\")\n",
    "df_test = TabularDataset(data=\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>also_buy</th>\n",
       "      <th>brand</th>\n",
       "      <th>rank</th>\n",
       "      <th>also_view</th>\n",
       "      <th>main_cat</th>\n",
       "      <th>Price</th>\n",
       "      <th>asin</th>\n",
       "      <th>details</th>\n",
       "      <th>descriptionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>Books\" /&gt;</td>\n",
       "      <td>[]</td>\n",
       "      <td>Joan M. Lexau</td>\n",
       "      <td>1,683,587 in Books (</td>\n",
       "      <td>['0590457292']</td>\n",
       "      <td>Books</td>\n",
       "      <td>5.48</td>\n",
       "      <td>B001D4OHQA</td>\n",
       "      <td>{'Publisher:': 'Scholastic (1974)', 'Language:...</td>\n",
       "      <td>Staining on cover, minimal wear and creasing. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['Books', 'Education &amp; Teaching', 'Schools &amp; T...</td>\n",
       "      <td>The Core Knowledge Sequence Content and Skill ...</td>\n",
       "      <td>['0325008957', '1138188492', '1890517208', '14...</td>\n",
       "      <td>Core Knowledge Foundation</td>\n",
       "      <td>974,014 in Books (</td>\n",
       "      <td>['0385316402', '1890517208', '1933486058', '19...</td>\n",
       "      <td>Books</td>\n",
       "      <td>21.40</td>\n",
       "      <td>B0071QRBFS</td>\n",
       "      <td>{'Paperback:': '400 pages', 'Publisher:': 'Cor...</td>\n",
       "      <td>A double volume with two &amp;quot;front covers.&amp;q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td>Stranger In The Woods</td>\n",
       "      <td>[]</td>\n",
       "      <td>Leah Fried</td>\n",
       "      <td>17,588,750 in Books (</td>\n",
       "      <td>[]</td>\n",
       "      <td>Books</td>\n",
       "      <td>17.00</td>\n",
       "      <td>965906523X</td>\n",
       "      <td>{'Hardcover:': '202 pages', 'Publisher:': 'Fel...</td>\n",
       "      <td>Stranger in the woods is a dramatic tale of co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>Hansel and Gretel :  A Fairy Opera, Vocal Score</td>\n",
       "      <td>[]</td>\n",
       "      <td>Adelheid ; Bache, Constance ; Humperdinck, E. ...</td>\n",
       "      <td>3,680,123 in Books (</td>\n",
       "      <td>['0793506603']</td>\n",
       "      <td>Books</td>\n",
       "      <td>10.95</td>\n",
       "      <td>B0011ZV86I</td>\n",
       "      <td>{'Publisher:': 'G. Schirmer, Inc. (1957)', 'AS...</td>\n",
       "      <td>Complete vocal score, words and music.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['Books', 'History', 'Asia']</td>\n",
       "      <td>Genghis Khan - Conqueror Of The World</td>\n",
       "      <td>[]</td>\n",
       "      <td>Leo De Hartog</td>\n",
       "      <td>5,083,249 in Books (</td>\n",
       "      <td>[]</td>\n",
       "      <td>Books</td>\n",
       "      <td>3.50</td>\n",
       "      <td>B001LIQC7A</td>\n",
       "      <td>{'Hardcover:': '230 pages', 'Publisher:': 'Bar...</td>\n",
       "      <td>a great biography of Ghengis Khan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            category  \\\n",
       "0                                                 []   \n",
       "1  ['Books', 'Education & Teaching', 'Schools & T...   \n",
       "2                                                 []   \n",
       "3                                                 []   \n",
       "4                       ['Books', 'History', 'Asia']   \n",
       "\n",
       "                                               title  \\\n",
       "0                                          Books\" />   \n",
       "1  The Core Knowledge Sequence Content and Skill ...   \n",
       "2                              Stranger In The Woods   \n",
       "3    Hansel and Gretel :  A Fairy Opera, Vocal Score   \n",
       "4              Genghis Khan - Conqueror Of The World   \n",
       "\n",
       "                                            also_buy  \\\n",
       "0                                                 []   \n",
       "1  ['0325008957', '1138188492', '1890517208', '14...   \n",
       "2                                                 []   \n",
       "3                                                 []   \n",
       "4                                                 []   \n",
       "\n",
       "                                               brand                   rank  \\\n",
       "0                                      Joan M. Lexau   1,683,587 in Books (   \n",
       "1                          Core Knowledge Foundation     974,014 in Books (   \n",
       "2                                         Leah Fried  17,588,750 in Books (   \n",
       "3  Adelheid ; Bache, Constance ; Humperdinck, E. ...   3,680,123 in Books (   \n",
       "4                                      Leo De Hartog   5,083,249 in Books (   \n",
       "\n",
       "                                           also_view main_cat  Price  \\\n",
       "0                                     ['0590457292']    Books   5.48   \n",
       "1  ['0385316402', '1890517208', '1933486058', '19...    Books  21.40   \n",
       "2                                                 []    Books  17.00   \n",
       "3                                     ['0793506603']    Books  10.95   \n",
       "4                                                 []    Books   3.50   \n",
       "\n",
       "         asin                                            details  \\\n",
       "0  B001D4OHQA  {'Publisher:': 'Scholastic (1974)', 'Language:...   \n",
       "1  B0071QRBFS  {'Paperback:': '400 pages', 'Publisher:': 'Cor...   \n",
       "2  965906523X  {'Hardcover:': '202 pages', 'Publisher:': 'Fel...   \n",
       "3  B0011ZV86I  {'Publisher:': 'G. Schirmer, Inc. (1957)', 'AS...   \n",
       "4  B001LIQC7A  {'Hardcover:': '230 pages', 'Publisher:': 'Bar...   \n",
       "\n",
       "                                   descriptionstring  \n",
       "0  Staining on cover, minimal wear and creasing. ...  \n",
       "1  A double volume with two &quot;front covers.&q...  \n",
       "2  Stranger in the woods is a dramatic tale of co...  \n",
       "3             Complete vocal score, words and music.  \n",
       "4                  a great biography of Ghengis Khan  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>also_buy</th>\n",
       "      <th>brand</th>\n",
       "      <th>rank</th>\n",
       "      <th>also_view</th>\n",
       "      <th>main_cat</th>\n",
       "      <th>Price</th>\n",
       "      <th>asin</th>\n",
       "      <th>details</th>\n",
       "      <th>descriptionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>Books\" /&gt;</td>\n",
       "      <td>[]</td>\n",
       "      <td>Joan M. Lexau</td>\n",
       "      <td>1,683,587 in Books (</td>\n",
       "      <td>['0590457292']</td>\n",
       "      <td>Books</td>\n",
       "      <td>5.48</td>\n",
       "      <td>B001D4OHQA</td>\n",
       "      <td>{'Publisher:': 'Scholastic (1974)', 'Language:...</td>\n",
       "      <td>Staining on cover, minimal wear and creasing. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['Books', 'Education &amp; Teaching', 'Schools &amp; T...</td>\n",
       "      <td>The Core Knowledge Sequence Content and Skill ...</td>\n",
       "      <td>['0325008957', '1138188492', '1890517208', '14...</td>\n",
       "      <td>Core Knowledge Foundation</td>\n",
       "      <td>974,014 in Books (</td>\n",
       "      <td>['0385316402', '1890517208', '1933486058', '19...</td>\n",
       "      <td>Books</td>\n",
       "      <td>21.40</td>\n",
       "      <td>B0071QRBFS</td>\n",
       "      <td>{'Paperback:': '400 pages', 'Publisher:': 'Cor...</td>\n",
       "      <td>A double volume with two &amp;quot;front covers.&amp;q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td>Stranger In The Woods</td>\n",
       "      <td>[]</td>\n",
       "      <td>Leah Fried</td>\n",
       "      <td>17,588,750 in Books (</td>\n",
       "      <td>[]</td>\n",
       "      <td>Books</td>\n",
       "      <td>17.00</td>\n",
       "      <td>965906523X</td>\n",
       "      <td>{'Hardcover:': '202 pages', 'Publisher:': 'Fel...</td>\n",
       "      <td>Stranger in the woods is a dramatic tale of co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>Hansel and Gretel :  A Fairy Opera, Vocal Score</td>\n",
       "      <td>[]</td>\n",
       "      <td>Adelheid ; Bache, Constance ; Humperdinck, E. ...</td>\n",
       "      <td>3,680,123 in Books (</td>\n",
       "      <td>['0793506603']</td>\n",
       "      <td>Books</td>\n",
       "      <td>10.95</td>\n",
       "      <td>B0011ZV86I</td>\n",
       "      <td>{'Publisher:': 'G. Schirmer, Inc. (1957)', 'AS...</td>\n",
       "      <td>Complete vocal score, words and music.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['Books', 'History', 'Asia']</td>\n",
       "      <td>Genghis Khan - Conqueror Of The World</td>\n",
       "      <td>[]</td>\n",
       "      <td>Leo De Hartog</td>\n",
       "      <td>5,083,249 in Books (</td>\n",
       "      <td>[]</td>\n",
       "      <td>Books</td>\n",
       "      <td>3.50</td>\n",
       "      <td>B001LIQC7A</td>\n",
       "      <td>{'Hardcover:': '230 pages', 'Publisher:': 'Bar...</td>\n",
       "      <td>a great biography of Ghengis Khan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            category  \\\n",
       "0                                                 []   \n",
       "1  ['Books', 'Education & Teaching', 'Schools & T...   \n",
       "2                                                 []   \n",
       "3                                                 []   \n",
       "4                       ['Books', 'History', 'Asia']   \n",
       "\n",
       "                                               title  \\\n",
       "0                                          Books\" />   \n",
       "1  The Core Knowledge Sequence Content and Skill ...   \n",
       "2                              Stranger In The Woods   \n",
       "3    Hansel and Gretel :  A Fairy Opera, Vocal Score   \n",
       "4              Genghis Khan - Conqueror Of The World   \n",
       "\n",
       "                                            also_buy  \\\n",
       "0                                                 []   \n",
       "1  ['0325008957', '1138188492', '1890517208', '14...   \n",
       "2                                                 []   \n",
       "3                                                 []   \n",
       "4                                                 []   \n",
       "\n",
       "                                               brand                   rank  \\\n",
       "0                                      Joan M. Lexau   1,683,587 in Books (   \n",
       "1                          Core Knowledge Foundation     974,014 in Books (   \n",
       "2                                         Leah Fried  17,588,750 in Books (   \n",
       "3  Adelheid ; Bache, Constance ; Humperdinck, E. ...   3,680,123 in Books (   \n",
       "4                                      Leo De Hartog   5,083,249 in Books (   \n",
       "\n",
       "                                           also_view main_cat  Price  \\\n",
       "0                                     ['0590457292']    Books   5.48   \n",
       "1  ['0385316402', '1890517208', '1933486058', '19...    Books  21.40   \n",
       "2                                                 []    Books  17.00   \n",
       "3                                     ['0793506603']    Books  10.95   \n",
       "4                                                 []    Books   3.50   \n",
       "\n",
       "         asin                                            details  \\\n",
       "0  B001D4OHQA  {'Publisher:': 'Scholastic (1974)', 'Language:...   \n",
       "1  B0071QRBFS  {'Paperback:': '400 pages', 'Publisher:': 'Cor...   \n",
       "2  965906523X  {'Hardcover:': '202 pages', 'Publisher:': 'Fel...   \n",
       "3  B0011ZV86I  {'Publisher:': 'G. Schirmer, Inc. (1957)', 'AS...   \n",
       "4  B001LIQC7A  {'Hardcover:': '230 pages', 'Publisher:': 'Bar...   \n",
       "\n",
       "                                   descriptionstring  \n",
       "0  Staining on cover, minimal wear and creasing. ...  \n",
       "1  A double volume with two &quot;front covers.&q...  \n",
       "2  Stranger in the woods is a dramatic tale of co...  \n",
       "3             Complete vocal score, words and music.  \n",
       "4                  a great biography of Ghengis Khan  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Model training with AutoGluon using the full dataset\n",
    "\n",
    "Now you can use AutoGluon to train a model with the full dataset.  \n",
    "\n",
    "Remember that you only need to provide the dataset and tell AutoGluon which column from the dataset you are trying to predict.\n",
    "\n",
    "**Note:** AutoGluon uses certain defaults. For example, AutoGluon uses `root_mean_squared_error` as an evaluation metric for regression problems. For more information, see [sklearn.metrics](https://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics) in the sklearn documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\"> \n",
    "    <h3><i>Try it yourself!</i></h3>\n",
    "    <p style=\"text-align:center; margin:auto;\"><img src=\"images/challenge.png\" alt=\"Challenge\" width=\"100\" /> </p>\n",
    "    <p style=\" text-align: center; margin: auto;\">In the following code cell, run the code to train the model with the full dataset.\n",
    "        <br><br><b>Important:</b> Use the <code>time_limit</code> parameter (in seconds) to limit the model training time to 20 minutes.\n",
    "</p>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why use a time limit?\n",
    "\n",
    "It shouldn't take more than 20 minutes for this model to train, but the time limit ensures that training will have enough time to create a better model without running for an undetermined amount of time. Setting the training time in this lab will allow you to work on other projects and come back when you know that training has completed.\n",
    "\n",
    "In a real-life situation, you can limit training time if you have a time or cost constraint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231031_185123/\"\n",
      "Preset alias specified: 'high_quality_fast_inference_only_refit' maps to 'high_quality'.\n",
      "Presets specified: ['high_quality_fast_inference_only_refit']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231031_185123/\"\n",
      "Preset alias specified: 'high_quality_fast_inference_only_refit' maps to 'high_quality'.\n",
      "Beginning AutoGluon training ... Time limit = 120s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231031_185123/\"\n",
      "AutoGluon Version:  0.8.0\n",
      "Presets specified: ['high_quality_fast_inference_only_refit']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 120s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231031_185123/\"\n",
      "AutoGluon Version:  0.8.0\n",
      "Python Version:     3.10.10\n",
      "Python Version:     3.10.10\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Mon Apr 24 23:34:06 UTC 2023\n",
      "Disk Space Avail:   19.62 GB / 20.96 GB (93.6%)\n",
      "Train Data Rows:    5000\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Mon Apr 24 23:34:06 UTC 2023\n",
      "Disk Space Avail:   19.62 GB / 20.96 GB (93.6%)\n",
      "Train Data Rows:    5000\n",
      "Train Data Columns: 10\n",
      "Label Column: Price\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (8537.94, 0.0, 45.08719000000001, 190.23545)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    14735.37 MB\n",
      "\tTrain Data (Original)  Memory Usage: 6.72 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "Train Data Columns: 10\n",
      "Label Column: Price\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (8537.94, 0.0, 45.08719000000001, 190.23545)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    14735.37 MB\n",
      "\tTrain Data (Original)  Memory Usage: 6.72 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['category', 'title', 'also_buy', 'brand', 'rank', 'also_view', 'details', 'descriptionstring']\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['category', 'title', 'also_buy', 'brand', 'rank', 'also_view', 'details', 'descriptionstring']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 2026\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 2026\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('object', [])       : 2 | ['main_cat', 'asin']\n",
      "\t\t('object', ['text']) : 8 | ['category', 'title', 'also_buy', 'brand', 'rank', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :    2 | ['main_cat', 'asin']\n",
      "\t\t('category', ['text_as_category'])  :    8 | ['category', 'title', 'also_buy', 'brand', 'rank', ...]\n",
      "\t\t('int', ['binned', 'text_special']) :  113 | ['category.char_count', 'category.word_count', 'category.capital_ratio', 'category.lower_ratio', 'category.special_ratio', ...]\n",
      "\t\t('int', ['text_ngram'])             : 1896 | ['__nlp__.000', '__nlp__.01', '__nlp__.10', '__nlp__.10 inches', '__nlp__.10 inches shipping', ...]\n",
      "\t28.3s = Fit runtime\n",
      "\t10 features in original data used to generate 2019 features in processed data.\n",
      "\t\t('object', [])       : 2 | ['main_cat', 'asin']\n",
      "\t\t('object', ['text']) : 8 | ['category', 'title', 'also_buy', 'brand', 'rank', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :    2 | ['main_cat', 'asin']\n",
      "\t\t('category', ['text_as_category'])  :    8 | ['category', 'title', 'also_buy', 'brand', 'rank', ...]\n",
      "\t\t('int', ['binned', 'text_special']) :  113 | ['category.char_count', 'category.word_count', 'category.capital_ratio', 'category.lower_ratio', 'category.special_ratio', ...]\n",
      "\t\t('int', ['text_ngram'])             : 1896 | ['__nlp__.000', '__nlp__.01', '__nlp__.10', '__nlp__.10 inches', '__nlp__.10 inches shipping', ...]\n",
      "\t28.3s = Fit runtime\n",
      "\t10 features in original data used to generate 2019 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 19.59 MB (0.1% of available memory)\n",
      "\tTrain Data (Processed) Memory Usage: 19.59 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 28.57s ...\n",
      "Data preprocessing and feature engineering runtime = 28.57s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 60.94s of the 91.39s of remaining time.\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 60.94s of the 91.39s of remaining time.\n",
      "\t-219.3796\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.38s\t = Training   runtime\n",
      "\t1.63s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 58.18s of the 88.63s of remaining time.\n",
      "\t-219.3796\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.38s\t = Training   runtime\n",
      "\t1.63s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 58.18s of the 88.63s of remaining time.\n",
      "\t-219.0026\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.55s\t = Training   runtime\n",
      "\t1.89s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 55.0s of the 85.45s of remaining time.\n",
      "\t-219.0026\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.55s\t = Training   runtime\n",
      "\t1.89s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 55.0s of the 85.45s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-189.9704\t = Validation score   (-root_mean_squared_error)\n",
      "\t-189.9704\t = Validation score   (-root_mean_squared_error)\n",
      "\t18.86s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "\t18.86s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 26.0s of the 56.44s of remaining time.\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 26.0s of the 56.44s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-190.0781\t = Validation score   (-root_mean_squared_error)\n",
      "\t20.37s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 1.52s of the 31.98s of remaining time.\n",
      "\t-190.0781\t = Validation score   (-root_mean_squared_error)\n",
      "\t20.37s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 1.52s of the 31.98s of remaining time.\n",
      "\t-215.4926\t = Validation score   (-root_mean_squared_error)\n",
      "\t-215.4926\t = Validation score   (-root_mean_squared_error)\n",
      "\t442.2s\t = Training   runtime\n",
      "\t5.47s\t = Validation runtime\n",
      "\t442.2s\t = Training   runtime\n",
      "\t5.47s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 91.43s of the -416.91s of remaining time.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 91.43s of the -416.91s of remaining time.\n",
      "\t-189.95080000000002\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.47s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "\t-189.95080000000002\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.47s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "No base models to train on, skipping auxiliary stack level 3...\n",
      "AutoGluon training complete, total runtime = 538.85s ... Best model: \"WeightedEnsemble_L2\"\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "No base models to train on, skipping auxiliary stack level 3...\n",
      "AutoGluon training complete, total runtime = 538.85s ... Best model: \"WeightedEnsemble_L2\"\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting model: KNeighborsUnif_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.38s\t = Training   runtime\n",
      "Fitting model: KNeighborsUnif_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t1.63s\t = Validation runtime\n",
      "\t0.38s\t = Training   runtime\n",
      "\t1.63s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "Fitting model: KNeighborsDist_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.55s\t = Training   runtime\n",
      "\t1.89s\t = Validation runtime\n",
      "\t0.55s\t = Training   runtime\n",
      "\t1.89s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t1.83s\t = Training   runtime\n",
      "\t1.83s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\t1.59s\t = Training   runtime\n",
      "\t1.59s\t = Training   runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t442.2s\t = Training   runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t5.47s\t = Validation runtime\n",
      "\t442.2s\t = Training   runtime\n",
      "\t5.47s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t0.47s\t = Training   runtime\n",
      "\t0.47s\t = Training   runtime\n",
      "Refit complete, total runtime = 5.56s\n",
      "Refit complete, total runtime = 5.56s\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231031_185123/\")\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231031_185123/\")\n"
     ]
    }
   ],
   "source": [
    "############### CODE HERE ###############\n",
    "\n",
    "predictor = TabularPredictor(label=\"Price\").fit(df_train, time_limit=120,presets='high_quality_fast_inference_only_refit')\n",
    "\n",
    "############## END OF CODE ##############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\">\n",
    "    <h3><i>Try it yourself!</i></h3>\n",
    "    <br>\n",
    "    <p style=\"text-align:center;margin:auto;\"><img src=\"images/challenge.png\" alt=\"Challenge\" width=\"100\" /> </p>\n",
    "    <p style=\" text-align: center; margin: auto;\">In the following code cell, run the code to use Autogluon's <code>leaderboard</code> function to look at the model predictor performance.</p>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          model  score_test   score_val  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0      WeightedEnsemble_L2_FULL -124.982522         NaN        0.319317            NaN  446.084923                 0.005616                     NaN           0.471807            2       True         12\n",
      "1        LightGBMXT_BAG_L1_FULL -125.073802         NaN        0.039224            NaN    1.830046                 0.039224                     NaN           1.830046            1       True          9\n",
      "2          LightGBM_BAG_L1_FULL -125.571535         NaN        0.038639            NaN    1.586017                 0.038639                     NaN           1.586017            1       True         10\n",
      "3    KNeighborsDist_BAG_L1_FULL -139.678819         NaN        0.224051       1.893061    0.547462                 0.224051                1.893061           0.547462            1       True          8\n",
      "4         KNeighborsDist_BAG_L1 -139.678819 -219.002610        0.310252       1.893061    0.547462                 0.310252                1.893061           0.547462            1       True          2\n",
      "5    KNeighborsUnif_BAG_L1_FULL -140.141279         NaN        0.219322       1.628846    0.384748                 0.219322                1.628846           0.384748            1       True          7\n",
      "6         KNeighborsUnif_BAG_L1 -140.141279 -219.379625        0.267471       1.628846    0.384748                 0.267471                1.628846           0.384748            1       True          1\n",
      "7   RandomForestMSE_BAG_L1_FULL -185.596909         NaN        0.235838       5.465621  442.197054                 0.235838                5.465621         442.197054            1       True         11\n",
      "8        RandomForestMSE_BAG_L1 -185.596909 -215.492575        0.256448       5.465621  442.197054                 0.256448                5.465621         442.197054            1       True          5\n",
      "9           WeightedEnsemble_L2         NaN -189.950752             NaN       6.058841  481.900651                      NaN                0.000749           0.471807            2      False          6\n",
      "10            LightGBMXT_BAG_L1         NaN -189.970404             NaN       0.300607   18.864959                      NaN                0.300607          18.864959            1      False          3\n",
      "11              LightGBM_BAG_L1         NaN -190.078126             NaN       0.291863   20.366831                      NaN                0.291863          20.366831            1      False          4\n",
      "                          model  score_test   score_val  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0      WeightedEnsemble_L2_FULL -124.982522         NaN        0.319317            NaN  446.084923                 0.005616                     NaN           0.471807            2       True         12\n",
      "1        LightGBMXT_BAG_L1_FULL -125.073802         NaN        0.039224            NaN    1.830046                 0.039224                     NaN           1.830046            1       True          9\n",
      "2          LightGBM_BAG_L1_FULL -125.571535         NaN        0.038639            NaN    1.586017                 0.038639                     NaN           1.586017            1       True         10\n",
      "3    KNeighborsDist_BAG_L1_FULL -139.678819         NaN        0.224051       1.893061    0.547462                 0.224051                1.893061           0.547462            1       True          8\n",
      "4         KNeighborsDist_BAG_L1 -139.678819 -219.002610        0.310252       1.893061    0.547462                 0.310252                1.893061           0.547462            1       True          2\n",
      "5    KNeighborsUnif_BAG_L1_FULL -140.141279         NaN        0.219322       1.628846    0.384748                 0.219322                1.628846           0.384748            1       True          7\n",
      "6         KNeighborsUnif_BAG_L1 -140.141279 -219.379625        0.267471       1.628846    0.384748                 0.267471                1.628846           0.384748            1       True          1\n",
      "7   RandomForestMSE_BAG_L1_FULL -185.596909         NaN        0.235838       5.465621  442.197054                 0.235838                5.465621         442.197054            1       True         11\n",
      "8        RandomForestMSE_BAG_L1 -185.596909 -215.492575        0.256448       5.465621  442.197054                 0.256448                5.465621         442.197054            1       True          5\n",
      "9           WeightedEnsemble_L2         NaN -189.950752             NaN       6.058841  481.900651                      NaN                0.000749           0.471807            2      False          6\n",
      "10            LightGBMXT_BAG_L1         NaN -189.970404             NaN       0.300607   18.864959                      NaN                0.300607          18.864959            1      False          3\n",
      "11              LightGBM_BAG_L1         NaN -190.078126             NaN       0.291863   20.366831                      NaN                0.291863          20.366831            1      False          4\n"
     ]
    }
   ],
   "source": [
    "############### CODE HERE ###############\n",
    "\n",
    "leaderboard = predictor.leaderboard(df_test)\n",
    "\n",
    "############## END OF CODE ##############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Model prediction with AutoGluon\n",
    "\n",
    "Now that your model is trained, you can use it to predict prices.\n",
    "\n",
    "You should always run a final model performance assessment by using data that the model didn't see (the test data). Test data is not used during training and can therefore give a performance assessment. You will use the test data to make predictions and generate a prediction file in the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\">\n",
    "    <h3><i>Try it yourself!</i></h3>\n",
    "    <br>\n",
    "    <p style=\"text-align:center;margin:auto;\"><img src=\"images/activity.png\" alt=\"Activity\" width=\"100\" /> </p>\n",
    "    <p style=\" text-align: center; margin: auto;\">To display part of the test dataset that you will use, run the following cell.</p>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>also_buy</th>\n",
       "      <th>brand</th>\n",
       "      <th>rank</th>\n",
       "      <th>also_view</th>\n",
       "      <th>main_cat</th>\n",
       "      <th>Price</th>\n",
       "      <th>asin</th>\n",
       "      <th>details</th>\n",
       "      <th>descriptionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['Books', 'Cookbooks, Food &amp; Wine']</td>\n",
       "      <td>Sanjeev Kapoor`s Traditional Indian Cuisines P...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Visit Amazon's Sanjeev Kapoor Page</td>\n",
       "      <td>4,203,444 in Books (</td>\n",
       "      <td>['1909487465', '8179916286']</td>\n",
       "      <td>Books</td>\n",
       "      <td>10.48</td>\n",
       "      <td>8179913112</td>\n",
       "      <td>{'Paperback:': '104 pages', 'Publisher:': 'Pop...</td>\n",
       "      <td>): Sanjeev kapoor is a celebrity par excellenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>Christopher Radko: The first decade, 1986-1995...</td>\n",
       "      <td>[]</td>\n",
       "      <td>aa</td>\n",
       "      <td>2,006,465 in Books (</td>\n",
       "      <td>['0609604767', '0740725114', '0977909905', '06...</td>\n",
       "      <td>Books</td>\n",
       "      <td>315.20</td>\n",
       "      <td>B0091PA87K</td>\n",
       "      <td>{'Publisher:': 'C. Radko for Starad, Inc; 2512...</td>\n",
       "      <td>Detailed pictorial look at the first 10 years ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['Books', 'Reference', 'Words, Language &amp; Gram...</td>\n",
       "      <td>Navaho Stories in Basic Vocabulary (A Dolch Ba...</td>\n",
       "      <td>['B0006AV7D8', 'B0007E0QTY']</td>\n",
       "      <td>Edward W. Dolch</td>\n",
       "      <td>6,550,510 in Books (</td>\n",
       "      <td>[]</td>\n",
       "      <td>Books</td>\n",
       "      <td>13.98</td>\n",
       "      <td>B000VF4TDS</td>\n",
       "      <td>{'Hardcover:': '165 pages', 'Publisher:': 'The...</td>\n",
       "      <td>Dust jacket notes about the Dolch Basic Vocabu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>The Cultural Monuments of Tibet's Outer Provin...</td>\n",
       "      <td>['9747534908', '9744800496', '9744800615']</td>\n",
       "      <td>Andreas Gruschke</td>\n",
       "      <td>4,368,852 in Books (</td>\n",
       "      <td>[]</td>\n",
       "      <td>Books</td>\n",
       "      <td>99.95</td>\n",
       "      <td>9747534592</td>\n",
       "      <td>{'Paperback:': '284 pages', 'Publisher:': 'Whi...</td>\n",
       "      <td>This book presents the fascinating world of no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>The Danger by Dick Francis</td>\n",
       "      <td>['0425204391', '042520846X', '0425237753', '04...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8,401,025 in Books (</td>\n",
       "      <td>['042520846X', '0425204391', '0425194973', '04...</td>\n",
       "      <td>Books</td>\n",
       "      <td>12.75</td>\n",
       "      <td>B004HMQY3Y</td>\n",
       "      <td>{'Publisher:': 'by Dick Francis (July 12, 2009...</td>\n",
       "      <td>Will be shipped from US. Used books may not in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            category  \\\n",
       "0                ['Books', 'Cookbooks, Food & Wine']   \n",
       "1                                                 []   \n",
       "2  ['Books', 'Reference', 'Words, Language & Gram...   \n",
       "3                                                 []   \n",
       "4                                                 []   \n",
       "\n",
       "                                               title  \\\n",
       "0  Sanjeev Kapoor`s Traditional Indian Cuisines P...   \n",
       "1  Christopher Radko: The first decade, 1986-1995...   \n",
       "2  Navaho Stories in Basic Vocabulary (A Dolch Ba...   \n",
       "3  The Cultural Monuments of Tibet's Outer Provin...   \n",
       "4                         The Danger by Dick Francis   \n",
       "\n",
       "                                            also_buy  \\\n",
       "0                                                 []   \n",
       "1                                                 []   \n",
       "2                       ['B0006AV7D8', 'B0007E0QTY']   \n",
       "3         ['9747534908', '9744800496', '9744800615']   \n",
       "4  ['0425204391', '042520846X', '0425237753', '04...   \n",
       "\n",
       "                                brand                  rank  \\\n",
       "0  Visit Amazon's Sanjeev Kapoor Page  4,203,444 in Books (   \n",
       "1                                  aa  2,006,465 in Books (   \n",
       "2                     Edward W. Dolch  6,550,510 in Books (   \n",
       "3                    Andreas Gruschke  4,368,852 in Books (   \n",
       "4                                 NaN  8,401,025 in Books (   \n",
       "\n",
       "                                           also_view main_cat   Price  \\\n",
       "0                       ['1909487465', '8179916286']    Books   10.48   \n",
       "1  ['0609604767', '0740725114', '0977909905', '06...    Books  315.20   \n",
       "2                                                 []    Books   13.98   \n",
       "3                                                 []    Books   99.95   \n",
       "4  ['042520846X', '0425204391', '0425194973', '04...    Books   12.75   \n",
       "\n",
       "         asin                                            details  \\\n",
       "0  8179913112  {'Paperback:': '104 pages', 'Publisher:': 'Pop...   \n",
       "1  B0091PA87K  {'Publisher:': 'C. Radko for Starad, Inc; 2512...   \n",
       "2  B000VF4TDS  {'Hardcover:': '165 pages', 'Publisher:': 'The...   \n",
       "3  9747534592  {'Paperback:': '284 pages', 'Publisher:': 'Whi...   \n",
       "4  B004HMQY3Y  {'Publisher:': 'by Dick Francis (July 12, 2009...   \n",
       "\n",
       "                                   descriptionstring  \n",
       "0  ): Sanjeev kapoor is a celebrity par excellenc...  \n",
       "1  Detailed pictorial look at the first 10 years ...  \n",
       "2  Dust jacket notes about the Dolch Basic Vocabu...  \n",
       "3  This book presents the fascinating world of no...  \n",
       "4  Will be shipped from US. Used books may not in...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>also_buy</th>\n",
       "      <th>brand</th>\n",
       "      <th>rank</th>\n",
       "      <th>also_view</th>\n",
       "      <th>main_cat</th>\n",
       "      <th>Price</th>\n",
       "      <th>asin</th>\n",
       "      <th>details</th>\n",
       "      <th>descriptionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['Books', 'Cookbooks, Food &amp; Wine']</td>\n",
       "      <td>Sanjeev Kapoor`s Traditional Indian Cuisines P...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Visit Amazon's Sanjeev Kapoor Page</td>\n",
       "      <td>4,203,444 in Books (</td>\n",
       "      <td>['1909487465', '8179916286']</td>\n",
       "      <td>Books</td>\n",
       "      <td>10.48</td>\n",
       "      <td>8179913112</td>\n",
       "      <td>{'Paperback:': '104 pages', 'Publisher:': 'Pop...</td>\n",
       "      <td>): Sanjeev kapoor is a celebrity par excellenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>Christopher Radko: The first decade, 1986-1995...</td>\n",
       "      <td>[]</td>\n",
       "      <td>aa</td>\n",
       "      <td>2,006,465 in Books (</td>\n",
       "      <td>['0609604767', '0740725114', '0977909905', '06...</td>\n",
       "      <td>Books</td>\n",
       "      <td>315.20</td>\n",
       "      <td>B0091PA87K</td>\n",
       "      <td>{'Publisher:': 'C. Radko for Starad, Inc; 2512...</td>\n",
       "      <td>Detailed pictorial look at the first 10 years ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['Books', 'Reference', 'Words, Language &amp; Gram...</td>\n",
       "      <td>Navaho Stories in Basic Vocabulary (A Dolch Ba...</td>\n",
       "      <td>['B0006AV7D8', 'B0007E0QTY']</td>\n",
       "      <td>Edward W. Dolch</td>\n",
       "      <td>6,550,510 in Books (</td>\n",
       "      <td>[]</td>\n",
       "      <td>Books</td>\n",
       "      <td>13.98</td>\n",
       "      <td>B000VF4TDS</td>\n",
       "      <td>{'Hardcover:': '165 pages', 'Publisher:': 'The...</td>\n",
       "      <td>Dust jacket notes about the Dolch Basic Vocabu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>The Cultural Monuments of Tibet's Outer Provin...</td>\n",
       "      <td>['9747534908', '9744800496', '9744800615']</td>\n",
       "      <td>Andreas Gruschke</td>\n",
       "      <td>4,368,852 in Books (</td>\n",
       "      <td>[]</td>\n",
       "      <td>Books</td>\n",
       "      <td>99.95</td>\n",
       "      <td>9747534592</td>\n",
       "      <td>{'Paperback:': '284 pages', 'Publisher:': 'Whi...</td>\n",
       "      <td>This book presents the fascinating world of no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>The Danger by Dick Francis</td>\n",
       "      <td>['0425204391', '042520846X', '0425237753', '04...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8,401,025 in Books (</td>\n",
       "      <td>['042520846X', '0425204391', '0425194973', '04...</td>\n",
       "      <td>Books</td>\n",
       "      <td>12.75</td>\n",
       "      <td>B004HMQY3Y</td>\n",
       "      <td>{'Publisher:': 'by Dick Francis (July 12, 2009...</td>\n",
       "      <td>Will be shipped from US. Used books may not in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            category  \\\n",
       "0                ['Books', 'Cookbooks, Food & Wine']   \n",
       "1                                                 []   \n",
       "2  ['Books', 'Reference', 'Words, Language & Gram...   \n",
       "3                                                 []   \n",
       "4                                                 []   \n",
       "\n",
       "                                               title  \\\n",
       "0  Sanjeev Kapoor`s Traditional Indian Cuisines P...   \n",
       "1  Christopher Radko: The first decade, 1986-1995...   \n",
       "2  Navaho Stories in Basic Vocabulary (A Dolch Ba...   \n",
       "3  The Cultural Monuments of Tibet's Outer Provin...   \n",
       "4                         The Danger by Dick Francis   \n",
       "\n",
       "                                            also_buy  \\\n",
       "0                                                 []   \n",
       "1                                                 []   \n",
       "2                       ['B0006AV7D8', 'B0007E0QTY']   \n",
       "3         ['9747534908', '9744800496', '9744800615']   \n",
       "4  ['0425204391', '042520846X', '0425237753', '04...   \n",
       "\n",
       "                                brand                  rank  \\\n",
       "0  Visit Amazon's Sanjeev Kapoor Page  4,203,444 in Books (   \n",
       "1                                  aa  2,006,465 in Books (   \n",
       "2                     Edward W. Dolch  6,550,510 in Books (   \n",
       "3                    Andreas Gruschke  4,368,852 in Books (   \n",
       "4                                 NaN  8,401,025 in Books (   \n",
       "\n",
       "                                           also_view main_cat   Price  \\\n",
       "0                       ['1909487465', '8179916286']    Books   10.48   \n",
       "1  ['0609604767', '0740725114', '0977909905', '06...    Books  315.20   \n",
       "2                                                 []    Books   13.98   \n",
       "3                                                 []    Books   99.95   \n",
       "4  ['042520846X', '0425204391', '0425194973', '04...    Books   12.75   \n",
       "\n",
       "         asin                                            details  \\\n",
       "0  8179913112  {'Paperback:': '104 pages', 'Publisher:': 'Pop...   \n",
       "1  B0091PA87K  {'Publisher:': 'C. Radko for Starad, Inc; 2512...   \n",
       "2  B000VF4TDS  {'Hardcover:': '165 pages', 'Publisher:': 'The...   \n",
       "3  9747534592  {'Paperback:': '284 pages', 'Publisher:': 'Whi...   \n",
       "4  B004HMQY3Y  {'Publisher:': 'by Dick Francis (July 12, 2009...   \n",
       "\n",
       "                                   descriptionstring  \n",
       "0  ): Sanjeev kapoor is a celebrity par excellenc...  \n",
       "1  Detailed pictorial look at the first 10 years ...  \n",
       "2  Dust jacket notes about the Dolch Basic Vocabu...  \n",
       "3  This book presents the fascinating world of no...  \n",
       "4  Will be shipped from US. Used books may not in...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\">\n",
    "    <h3><i>Try it yourself!</i></h3>\n",
    "    <br>\n",
    "    <p style=\"text-align:center;margin:auto;\"><img src=\"images/challenge.png\" alt=\"Challenge\" width=\"100\" /> </p>\n",
    "    <p style=\" text-align: center; margin: auto;\">In the following code cell, run the code to use your trained model to make a prediction on the test dataset and save your predictions as a list</p>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:   [39.634517669677734, 58.670875549316406, 37.64510726928711, 60.65604782104492, 43.39190673828125]\n",
      "Predictions:   [39.634517669677734, 58.670875549316406, 37.64510726928711, 60.65604782104492, 43.39190673828125]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: root_mean_squared_error on test data: -124.98252220818797\n",
      "\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
      "Evaluation: root_mean_squared_error on test data: -124.98252220818797\n",
      "\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"root_mean_squared_error\": -124.98252220818797\n",
      "}\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"root_mean_squared_error\": -124.98252220818797\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "############### CODE HERE ###############\n",
    "\n",
    "df_prediction = predictor.predict(df_test)\n",
    "print(\"Predictions:  \", list(df_prediction)[:5])\n",
    "perf = predictor.evaluate(df_test, auxiliary_metrics=False)\n",
    "\n",
    "############## END OF CODE ##############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\">\n",
    "    <h3><i>Try it yourself!</i></h3>\n",
    "    <br>\n",
    "    <p style=\"text-align:center;margin:auto;\"><img src=\"images/activity.png\" alt=\"Activity\" width=\"100\" /> </p>\n",
    "    <p style=\" text-align: center; margin: auto;\">One way to share the results of predictions for tabular data is to save a file. The file can be a simple .csv file that contains an ID to identify each data sample and the prediction value itself.</p>\n",
    "    <br>\n",
    "    <p style=\" text-align: center; margin: auto;\">To save your prediction file, run the following code cell. For this example, the ID is the <b>asin</b> column.</p>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** If you haven't created the trained model to make predictions on the test dataset, you won't have the `price_prediction` DataFrame that is needed to create the prediction file. Running the following cell will generate an error. If you receive the error, use the `.predict()` function on the test dataset to create the `price_prediction` DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define Pandas columns\n",
    "df_prediction = pd.DataFrame(columns=[\"ID\", \"Price\"])\n",
    "\n",
    "# Createthe ID column from the ID list\n",
    "df_prediction[\"ID\"] = df_test[\"asin\"].tolist()\n",
    "\n",
    "# Create label column from price prediction list\n",
    "df_prediction[\"Price\"] = price_prediction\n",
    "\n",
    "# Save as a .csv file\n",
    "df_prediction.to_csv(\"./prediction.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to see what the prediction data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8179913112</td>\n",
       "      <td>39.634518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B0091PA87K</td>\n",
       "      <td>58.670876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B000VF4TDS</td>\n",
       "      <td>37.645107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9747534592</td>\n",
       "      <td>60.656048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B004HMQY3Y</td>\n",
       "      <td>43.391907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID      Price\n",
       "0  8179913112  39.634518\n",
       "1  B0091PA87K  58.670876\n",
       "2  B000VF4TDS  37.645107\n",
       "3  9747534592  60.656048\n",
       "4  B004HMQY3Y  43.391907"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8179913112</td>\n",
       "      <td>39.634518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B0091PA87K</td>\n",
       "      <td>58.670876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B000VF4TDS</td>\n",
       "      <td>37.645107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9747534592</td>\n",
       "      <td>60.656048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B004HMQY3Y</td>\n",
       "      <td>43.391907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID      Price\n",
       "0  8179913112  39.634518\n",
       "1  B0091PA87K  58.670876\n",
       "2  B000VF4TDS  37.645107\n",
       "3  9747534592  60.656048\n",
       "4  B004HMQY3Y  43.391907"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prediction.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Conclusion\n",
    "\n",
    "You have now created a model with AutoGluon using the full dataset and made predictions using the updated model.\n",
    "\n",
    "## Next lab\n",
    "\n",
    "In the next lab, you will learn about using Jupyter notebooks for exploratory data analysis (EDA), particularly for categorical data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
